Objektrepräsentationen sind fundamental für viele Anwendungen in Computer Vision. Die vorliegende Arbeit präsentiert und evaluiert einen unüberwachten Ansatz, um eine kompositionelle Teilrepräsentation von Objekten zu lernen, welche die räumliche Form und die visuelle Erscheinung für jeden Objektteil trennt. Um die Faktoren von Form und Erscheinung zu trennen, wird Invarianz unter Transformationen des jeweils anderen Faktors angenommen. Zusätzlich wird verwendet, dass räumliche Form equivariant bezüglich räumlicher Transformationen ist. Diese Annahmen werden in eine Autoencoder Architektur eingebaut, die so konstruiert ist, dass eine lokale Interpretation der Objektteile gewahrt bleibt. \\
Die Methode weist dem Objekt Teile zu, die das Objekt konsistent und sinnvoll abdecken, ohne manuelle Überwachung oder a priori Annahmen über die Objektklasse zu benötigen.
Die Methode wird evaluiert auf einer Anzahl an herausfordernden Datensätzen, wobei die Objektklassen variieren: von menschlichen Gesichtern über menschliche Personen bis hin zu Hunden, Katzen und Vögeln. Das unüberwachte Lernen von Form wird evaluiert, indem aus den entdeckten Teilen Objektmarkierungen regressiert werden. Der neueste Stand der Forschung wird hierbei signifikant übertroffen. Darüber hinaus wird gezeigt, dass die Repräsentation tatsächlich in Form und Erscheinung aufspaltet und lokale Teile unabhängig voneinander lernt.
