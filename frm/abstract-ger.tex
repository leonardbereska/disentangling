Objektrepräsentationen sind von fundamentaler Bedeutung für viele Anwendungen in Computer Vision. Die vorliegende Arbeit präsentiert und evaluiert einen unüberwachten Ansatz, um eine kompositionelle Teilrepräsentation von Objekten zu lernen, welche die geometrische Form und die visuelle Erscheinung für jeden Objektteil trennt. Um die Faktoren von Form und Erscheinung zu trennen, wird gegenseitige Invarianz unter Transformationen des jeweils anderen Faktors angenommen. Zusätzlich wird verwendet, dass räumliche Form equivariant bezüglich räumlicher Transformationen ist. Diese Annahmen werden in eine Autoencoder Architektur eingebaut, die so konstruiert ist, dass eine lokale Interpretation der Objektteile gewahrt bleibt. \\
Die Methode weist dem Objekt konsistente Teile zu, die das Objekt sinnvoll abdecken, ohne manuelle Überwachung oder a priori Annahmen über die Objektklasse zu benötigen.
Wir evaluieren auf einer diversen Menge von herausfordernden Datensätzen, wobei die Objektklassen variieren: von menschlichen Gesichtern über menschliche Personen bis hin zu Hunden, Katzen und Vögeln. Das unüberwachte Lernen von Form wird evaluiert, indem aus den entdeckten Teilen, Objektmarkierungen regressiert werden. Der letzte Stand der Technik wir hierbei signifikant geschlagen. Wir zeigen darüber hinaus, dass die Repräsentation tatsächlich in Form und Erscheinung aufspaltet und lokale Teile unabhängig voneinander lernt.
