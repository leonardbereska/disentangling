\section{Related Work}

\textbf{Analysis-by-Synthesis} Capturing essential information about data in a representation by being able to generate it is the rationale behind generative modelling. Currently the approaches in this direction are defined by adversarial \cite{Goodfellow:2014td} and autoencoding \cite{Kingma:2013tz} model formulations. Recently, the endeavour for disentangling explanatory factors in the latent representation is being made explicit in the objective functions \cite{Burgess:2018uf, Chen:2016tp} of these models. So far, however, these attempts are limited to rigid objects without articulation and disentangle holistic image factors like illumination, object rotation or total shape and global appearance. \todo{Denton:2017uf} \ % TODO ref disentangling models % TODO capsules

\textbf{Part-based representation learning} Describing an object as an assembly of parts is a classical paradigm for learning an object representation in computer vision \cite{Ross:2006uc} with linkage to human perceptual theories \cite{Biederman:1987tc}. What constitutes a part, is the defining question in this scheme. Defining parts by e.g. (\emph{i}) visual/semantic features (object detection), or by (\emph{ii}) geometric shape, behavior under (\emph{iii}) viewpoint changes or (\emph{iv}) object articulation, in general leads to a different partition of the object. Recently, most part learning has been employed for object recognition, such as in \cite{Felzenszwalb:2010ve, Novotny:2017ta, Singh:2012un, Mesnil:2013hi, Yang:2016uo, Lam:2017ta} % other methods for discriminative -> recognition -> focus on visual factorization % ours for generative image modeling -> also structural aspects %\cite{DPM, constellation1,constellation2} combine parts with a probabilistic prior on their spatial arrangements. %Novotny et al. \cite{anchornet} find parts shared by similar categories to perform semantic matching. Mining of discriminative parts can be formulated as an clustering problem or an iterative refinement process \cite{partLearning2}.
To solve such a discriminative task, parts will be based on the semantic connection to the object and can ignore their spatial arrangement and articulation of the object instance. Our method instead is driven by a generative process and aims at more generic modeling of the object as a whole. Hence, parts have to encode both spatial structure and visual appearance accurately. To our best knowledge unsupervised part learning and the proposed split in shape and appearance description for a part has only been used in pre-deep learning approaches \cite{Ross:2006uc, Nguyen:2013vk, Cootes:1998tn}. \

\textbf{Disentangling pose and appearance} Factorizing an object representation into pose and appearance is another traditional ansatz for represenation learning. % to understand an object. Recently, a lot of progress has been made in this direction by conditioning generative models on pose information \cite{Esser:2018ue, Ma:2017wq, deBem:2018wp, Ma:2017uu, Siarohin:2018wk, Balakrishnan:2018wo}. In contrast to these pose-supervised approaches, we learn the pose representation without any labels. \ % In addition Most of appearance globally and not on the level of parts. \

\textbf{Landmark detection} There is an extensive literature on landmarks as compact representations of object structure. Most approaches, however, make use of manual landmark annotations as supervision signal. Supervised methods have been successfully applied to human faces %active appearance [10, 38, 11], template-based methods [42, 83], regression-based methods [61, 12, 7, 48], deep [55, 77, 81, 82, 75, 70, 68, 33, 71] and human bodies [73, 60, 39].\ \cite{Wu:2017vc, Ranjan:2016vv, Yu:2016vi, Zhang:2016vx, Zhu:2015tz, Zhang:2014wy, Pedersoli:2014ta} and human bodies \cite{Ionescu:2011ue, Toshev:2014tp, Pfister:2015uo, Wei:2016ws, Newell:2016vq, Lim:2018uo, Cao:2017vv} as well as birds.\\todo{\cite{https://arxiv.org/pdf/1605.01014.pdf}} %Unsupervised methods for landmark learning quit the need for labeled datasets and can thus access arbitrary object categories. %For the task of unsupervised landmark learning there are, to our best knowledge, currently only two methods: \todo{add jakab18 } Thewlis et al. \cite{Thewlis:2017wi} proposed enforcing equivariance of landmark locations under artificial transformations applied on images. The equivariance idea had been formulated by them in earlier work \cite{Lenc:2016tz} and has been extended to learn a dense object-centric coordinate frame \cite{Thewlis:2017wg}. The work of Zhang et al. \cite{Zhang:2018vz} is more similar to our work: they extended the equivariance task by a reconstruction task in an auto-encoder framework, giving visual meaning to the landmarks. However, it relies on a separation constraint in order to avoid the collapse of landmarks. %under the force of equivariance. This constraint results in an artificial, rather grid-like layout of landmarks, that does not scale to complex articulations.\ %An equivariance constraint alone is detecting landmarks at easily discriminable object locations. The equivariant landmarks gain visual meaning, if they are used for image modeling in an additional reconstruction task (Zhang et al. \cite{zhang18}). %Pedersoli et al. \cite{facialLM1} use deformation fields for head pose and landmark detection, \cite{facialLM2} employ an iterative refinement algorithm, \cite{facialLM3} learn an ensemble of estimators and a deep learning approach to successfully apply multi-stage frameworks \cite{facialLMCNN1,facialLMCNN2,facialLM_CNN3} \todo{last sentence not clear to me}. Regression-based landmark learning proved to be so effective for pose estimation \cite{hourglass,deepPose,poseMachines,poseAffinityFields}, that it is considered to be a solved problem now. % and Yu et al. \todo{where is the fucking reference??https://arxiv.org/pdf/1605.01014.pdf } use a shape basis for general object landmark detection. \ %Zhang et al. \cite{zhang18} \todo{read Zhang, what is really the difference?} extend the equivariance constraint by a reconstruction task. To prevent the collapse of of the learned landmarks to one point, both works employ an artificial separation loss. This results in a grid-like, rather inflexible layout of landmarks, that does not scale to complex object articulation. %work using an auto-encoding based method.% but still suffer from the diversity constraint, especially in the presence of strong object articulation. %Our approach also builds on equivariance in combination with generative modeling, but In contrast, our method explicitly aims at decoupling structure and appearance of the object. Thus, for optimal reconstruction, our model has to make use of the provided shape information efficiently, which leads to a meaningful object coverage. \ Building on the reconstruction objective introduced by \cite{Zhang:2018vz}, another work by Jakab et al. \cite{Jakab:2018wc} proposes conditioning the generation on a landmark representation from another image. A global feature representation of one image is combined with the landmark positions of another image to reconstruct the latter image. This conditioning is similar to our two-stream formulation in essence. In contrast to our work, structure (as landmark positions) and visual appearance description is global, whereas we partition an object explicitly as combination of local parts with each its own structure \textit{and} appearance. This further factorization encourages equivariance and assignment consistency of each part in our formulation.
