\IEEEPARstart{C}{omputer} vision is the endeavour to automatically discern patterns in images, which reflect structures and processes in the physical world.
Capturing the causal elements that generate an image is a long-standing goal of computer vision and is driving the search for image representations which disentangle these causal factors from each other.
On the one hand there are pragmatic reasons to aim at extracting disentangled factors from images: to successfully transfer a representation between different tasks, typically only a few factors are relevant \cite{Bengio:2013bu}.
Efficient transfer and multi-task learning should account for this.
On the other hand, learning to capture external mechanisms in appropriate internal representations, can be seen as a goal in its own.
It enables machines to reason about the world \cite{Pearl:2018im}.
In addition, once disentangled, a factor can be manipulated individually to make a targeted change.
Thought experiments like \textit{"imagine, how ridiculous you would look, if you wore that hot pants"} are managable tasks for human imagination, but are out of the league for currently used generative image models \cite{Goodfellow:2014td, Kingma:2013tz}, that typically rely on uninterpretable vector spaces with entangled dimensions.
In the sense of generative modelling, disentangling factors could as well lead the way from a science of images to a science of imagination \cite{Mahadevan:2018tz}.
